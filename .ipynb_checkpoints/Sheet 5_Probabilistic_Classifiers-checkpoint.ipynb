{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 5: Probabilistic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question on Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Use the Face-data set we used in Assignment 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports cell \n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Method to loadImages into list from a given path parameter.\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "    foldersList = listdir(path)\n",
    "    loadedImages = []\n",
    "    for folder in foldersList :\n",
    "        imagesList = listdir(path+folder)\n",
    "        for image in imagesList:\n",
    "            img = PImage.open(path +folder+'/'+ image)\n",
    "            loadedImages.append(img)\n",
    "    return loadedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our Faces dataset.\n",
    "path = \"../Projects/Face-Recoginition/orl_faces/\"\n",
    "imgs = loadImages(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the images list into data matrix.\n",
    "dataMatrix = np.arange(4121600).reshape(400,10304)\n",
    "j=0\n",
    "label = []\n",
    "for i in range(0,400) :\n",
    "    if(i%10 == 0):\n",
    "        j = j+1\n",
    "    dataMatrix[i] = np.array(imgs[i]).flatten()     #flatten() method is used to unroll the matrix into vector\n",
    "    label.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (50 - 50) split is used here. \n",
    "#Even instances for test set. \n",
    "#Odd instances for train set.\n",
    "trainSet=np.arange(200*10304).reshape(200,10304)\n",
    "testSet=np.arange(200*10304).reshape(200,10304)\n",
    "trainLabel=[]\n",
    "testLabel=[]\n",
    "j,k=0,0\n",
    "for i in range(0,400):\n",
    "    if(i%2==0):\n",
    "        testSet[j]=dataMatrix[i]\n",
    "        testLabel.append(label[i])\n",
    "        j+=1\n",
    "    else:\n",
    "        trainSet[k]=dataMatrix[i]\n",
    "        trainLabel.append(label[i])\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Implement your Naive Bayes Classifier. You have now a long feature vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes(data_set,label_vec):\n",
    "    n = data_set.shape[0]\n",
    "    d = data_set.shape[1]\n",
    "    data_classes = {}\n",
    "    #separate data into classes. Each class is stored into a matrix.\n",
    "    for i in range(n):\n",
    "        if(label_vec[i] not in data_classes):\n",
    "            data_classes[label_vec[i]] = np.array([data_set[i]])\n",
    "        else:\n",
    "            data_classes[label_vec[i]] = np.concatenate([data_classes[label_vec[i]],[data_set[i]]])\n",
    "            \n",
    "    #compute for each class: cardinality or size, \n",
    "    #   it's prior probability, \n",
    "    #   it's mean, it's centered data matrix,\n",
    "    #\n",
    "    n_classes = len(data_classes)\n",
    "    size_classes = np.zeros(n_classes)\n",
    "    prior_prob = np.zeros(n_classes)\n",
    "    mean_classes = np.zeros((n_classes,d))\n",
    "    var_classes = np.zeros((n_classes,d))\n",
    "    for i in range(1,n_classes+1):\n",
    "        size_classes[i-1] = data_classes[i].shape[0]\n",
    "        prior_prob[i-1] = size_classes[i-1]/n\n",
    "        mean_classes[i-1] = np.mean(data_classes[i], axis=0)\n",
    "        var_classes[i-1] = np.var(data_classes[i], axis=0)        \n",
    "       # for j in range(d):\n",
    "        #    var_classes[i-1,j] = (1/(size_classes[i-1])) * (np.dot(data_classes[i][:,j],data_classes[i][:,j]))\n",
    "            \n",
    "    return prior_prob,mean_classes,var_classes\n",
    "\n",
    "def calculateProbability(x, mean, var):\n",
    "    if(var == 0): return 1.0\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2.0*var)))\n",
    "    return (1 / (math.sqrt(2.0*math.pi) * math.sqrt(var))) * exponent     \n",
    "        \n",
    "def Predict(test_point,prior_prob,mean_classes,var_classes):\n",
    "    n_classes = mean_classes.shape[0]\n",
    "    d = mean_classes.shape[1]\n",
    "    posterior_prob = np.zeros(n_classes)\n",
    "    epsilon = 0.0001\n",
    "    likelihood = 0\n",
    "    for i in range(n_classes):\n",
    "        likelihood = 0\n",
    "        for j in range(d):\n",
    "            probabiltiy = calculateProbability(test_point[j],mean_classes[i,j],var_classes[i,j])+epsilon\n",
    "            likelihood += np.log(probabiltiy)\n",
    "        posterior_prob[i] = likelihood + np.log(prior_prob[i])\n",
    "    \n",
    "    return np.argmax(posterior_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob,mean_classes,var_classes = NaiveBayes(trainSet,trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predict = np.zeros(testSet.shape[0])\n",
    "for i in range(testSet.shape[0]):\n",
    "    label_predict[i] = Predict(testSet[i],prior_prob,mean_classes,var_classes)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Report Classification Accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(testLabel,label_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Show the confusion matrix and the error cases. Discuss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0]\n",
      " [0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  5 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 5 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      "  0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(confusion_matrix(testLabel,label_predict))\n",
    "np.set_printoptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Appy Naive Bayes on the first 40 Components using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data_set,r):\n",
    "    #calculate mean face of the training set.\n",
    "    mean = np.mean(data_set,axis=0)\n",
    "    #subtract the mean from the training set.\n",
    "    center_data = data_set-mean\n",
    "    #compute the covariance matrix from obtained centered data matrix.\n",
    "    cov_matrix=np.cov(center_data, rowvar=False, bias=True)\n",
    "    #compute eigen vectors and values from obtained covariance matrix.\n",
    "    eigVal,eigVectMatrix=np.linalg.eigh(cov_matrix)\n",
    "    #flip both eigen values and vectors in order to be sorted descendingly.\n",
    "    eigVal=np.flip(eigVal,axis=0)\n",
    "    eigVectMatrix=np.flip(eigVectMatrix,axis=1)\n",
    "    return eigVal[0:r],eigVectMatrix[:,0:r] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvalues, eigvectors = PCA(trainSet,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projecting the data instances on the new basis.\n",
    "reduced_trainset = (eigvectors.T @ trainSet.T)\n",
    "reduced_testset = (eigvectors.T @ testSet.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob,mean_classes,var_classes = NaiveBayes(reduced_trainset.T,trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predict = np.zeros(testSet.shape[0])\n",
    "for i in range(testSet.shape[0]):\n",
    "    label_predict[i] = Predict(reduced_testset.T[i],prior_prob,mean_classes,var_classes)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f. Compare results with what you obtained in c,d.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(testLabel,label_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 1]\n",
      " [0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 2 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 1 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  5 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n",
      "  0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 5 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0\n",
      "  0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(confusion_matrix(testLabel,label_predict))\n",
    "np.set_printoptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Midterm 2 Question (Laptops were allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = np.array([[2,6],[3,3],[3,5],[4,3],[4,4],[4,5],\n",
    "                        [5,3],[5,5],[6,2],[6,4],[6,6],[7,2],[7,3],[7,4],[7,5],\n",
    "                        [8,4],[9,2],[9,3],[10,1],[10,3],[10,5],\n",
    "                        [11,3],[11,4],[12,2],[13,5]])\n",
    "data_label = np.array([1,2,1,2,1,2,1,2,1,1,1,3,2,2,2,1,1,1,3,3,3,3,3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob,mean_classes,var_classes = NaiveBayes(data_matrix,data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Compute the prior for the three classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability of C1 = 0.4\n",
      "Prior probability of C2 = 0.28\n",
      "Prior probability of C3 = 0.32\n"
     ]
    }
   ],
   "source": [
    "print(\"Prior probability of C1 = {0}\\nPrior probability of C2 = {1}\\nPrior probability of C3 = {2}\".format(prior_prob[0],prior_prob[1],prior_prob[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Compute the mean and covariance matrix for C1, C2 and C3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of C1 = [5.8 3.9]\n",
      "Mean of C2 = [5.28571429 4.        ]\n",
      "Mean of C3 = [10.5    3.125]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of C1 = {0}\\nMean of C2 = {1}\\nMean of C3 = {2}\".format(mean_classes[0],mean_classes[1],mean_classes[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of C1 = [5.8 3.9]\n",
      "Variance of C2 = [5.28571429 4.        ]\n",
      "Variance of C3 = [10.5    3.125]\n"
     ]
    }
   ],
   "source": [
    "print(\"Variance of C1 = {0}\\nVariance of C2 = {1}\\nVariance of C3 = {2}\".format(mean_classes[0],mean_classes[1],mean_classes[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Use the Naive Bayes classifier to classify the samples p1=(6,5), p2=(9,4), p3=(8,5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point (6,5) is Class 2\n",
      "Point (9,4) is Class 3\n",
      "Point (8,5) is Class 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Point (6,5) is Class\",Predict([6,5],prior_prob,mean_classes,var_classes)+1)\n",
    "print(\"Point (9,4) is Class\",Predict([9,4],prior_prob,mean_classes,var_classes)+1)\n",
    "print(\"Point (8,5) is Class\",Predict([8,5],prior_prob,mean_classes,var_classes)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Suppose we have a new feature for each instance defined as below\n",
    "If a point is inside the rectangle specified by the (0,0) and (x,y) then the\n",
    "feature value will equal IN, otherwise the feature value will equal OUT.\n",
    "Let us have three regions defined as above using the endpoints (3,2),\n",
    "(6,4) and (9,6).\n",
    "Use the Naive Bayes classifier on the three new features defined on e part\n",
    "to label the samples p1=(6,5), p2=(9,4), p3=(8,5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_matrix = np.array([[2,6],[3,3],[3,5],[4,3],[4,4],[4,5],\n",
    "                        [5,3],[5,5],[6,2],[6,4],[6,6],[7,2],[7,3],[7,4],[7,5],\n",
    "                        [8,4],[9,2],[9,3],[10,1],[10,3],[10,5],\n",
    "                        [11,3],[11,4],[12,2],[13,5]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
